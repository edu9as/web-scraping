{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Searching for papers in PubMed using Python\n",
    "\n",
    "You can execute this code in <a href=\"https://colab.research.google.com/github/edu9as/web-scraping/blob/master/Searching-For-Papers-In-PubMed.ipynb\">**Google Colab**</a>\n",
    "\n",
    "PubMed is an open-access search engine that allows the user to look for the contents of MEDLINE database, and also other magazines not included in this database. Its use is very extended among the scientific community, specifically in the life sciences area.\n",
    "\n",
    "In this notebook, I am using web-scraping to look for the PubMed URL of a given paper and to obtain the abstract, title, authors and journal of publication of all the papers that are related with a topic of my interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load libraries\n",
    "\n",
    "Only three libraries are needed here: **requests**, **BeautifulSoup** and **time**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Examine PubMed conditions for crawling\n",
    "\n",
    "Because we are scraping PubMed domain, first of all we have to look at its ```robots.txt``` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-agent: *\n",
      "Crawl-delay: 1\n",
      "Disallow: /api\n",
      "Disallow: /rss\n",
      "Disallow: /advanced/adv-suggestions/\n",
      "Disallow: /terms/\n",
      "Disallow: /addToHistory/\n",
      "Disallow: /deleteHistory/\n",
      "Disallow: /downloadHistory/\n",
      "Disallow: /deleteHistoryRecord/\n",
      "Disallow: /historyCacheExists/\n",
      "Disallow: /*/references/\n",
      "Disallow: /*/citations/\n",
      "Disallow: /*/export/\n",
      "Disallow: /*/citedby/\n",
      "Disallow: /*/similar/\n",
      "Disallow: /*/adj-nav/\n",
      "Disallow: /ajax/\n",
      "Disallow: /clipboard/\n",
      "Disallow: /clipboard-next-page/\n",
      "Disallow: /health/\n",
      "Disallow: /deep-health-abstract/\n",
      "Disallow: /deep-health-search/\n",
      "Disallow: /deep-health-auth/\n",
      "Disallow: /error/400/\n",
      "Disallow: /error/403/\n",
      "Disallow: /error/404/\n",
      "Disallow: /error/500/\n",
      "Disallow: /results-export-ids/\n",
      "Disallow: /results-export-search-data/\n",
      "Disallow: /results-export-email-by-search-data/\n",
      "Disallow: /results-export-search-by-year/\n",
      "Disallow: /send-email/\n",
      "Disallow: /list-existing-collections/\n",
      "Disallow: /add-to-existing-collection/\n",
      "Disallow: /create-and-add-to-new-collection/\n",
      "Disallow: /toggle-favorites-collection/\n",
      "Disallow: /list-bibliography-delegates/\n",
      "Disallow: /add-to-bibliography/\n",
      "Disallow: /create-saved-search/\n",
      "Disallow: /create-rss-feed-url/\n",
      "Disallow: /searches/\n",
      "Disallow: /collections/\n",
      "Disallow: /more/\n",
      "Disallow: /suggestions/\n",
      "Disallow: /try-search-term/\n",
      "Disallow: /rss-feed/\n",
      "\n",
      "Sitemap: https://pubmed.ncbi.nlm.nih.gov/sitemap?p=index.xml\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(requests.get(\"https://pubmed.ncbi.nlm.nih.gov/robots.txt\").text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are only making requests of query results and PubMed publication entries, so we are free to get the information we want. However, we must wait 1 second after making any request to this domain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define some functions\n",
    "\n",
    "In this section, I am creating some functions that will be useful when dealing with PubMed webpages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Scrape PubMed query results webpage\n",
    "\n",
    "Given an HTML file with the results of a query in PubMed, this function will store the URL for each paper in the webpage in a dictionary and the information about the paper title, author(s) and journal in a tuple of lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_pubmed_query(url, file):\n",
    "    \"\"\"\n",
    "    Requests a PubMed query results webpage and extracts the URLs, title,\n",
    "    author(s) and journal of publication of all the papers.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    url : string\n",
    "        URL for querying PubMed.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    urls_dict : dictionary\n",
    "        A dictionary that associates the number (between 1 and 10) of each\n",
    "        paper in the webpage with the URL of each paper's PubMed entry.\n",
    "        \n",
    "    summary : tuple\n",
    "        Tuple containing three lists. These lists contain the titles, authors\n",
    "        and journals of the papers in the query results webpage.\n",
    "\n",
    "    \"\"\"\n",
    "    pubmed = get_webpage(url)\n",
    "    soup = bs(pubmed, \"html.parser\")\n",
    "    \n",
    "    papers = soup.findAll(\"div\", class_=\"docsum-content\")\n",
    "    urls = [paper.find(\"a\", class_=\"docsum-title\").get(\"href\")\n",
    "              for paper in papers]\n",
    "    \n",
    "    urls_dict = {str(i): urls[i] for i in range(len(urls))}\n",
    "    \n",
    "    \n",
    "    titles = [prepare_text(paper.find(\"a\", class_=\"docsum-title\"), \n",
    "                           encode = file)\n",
    "              for paper in papers]\n",
    "    authors = [prepare_text(paper.find(\"span\", class_=\"full-authors\"),\n",
    "                            encode = file)\n",
    "              for paper in papers]\n",
    "    journals = [prepare_text(paper.find(\"span\", \n",
    "                                        class_=\"short-journal-citation\"), \n",
    "                             encode = file)\n",
    "              for paper in papers]\n",
    "    \n",
    "    summary = (titles, authors, journals)\n",
    "    \n",
    "    return urls_dict, summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Print table from list of query results\n",
    "\n",
    "This function will render a nicely formatted table showing the title, author(s) and journal of the hits of the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_table_from_list(summary, line = 105):\n",
    "    \"\"\"\n",
    "    Given a tuple with the lists containing the papers information, renders a\n",
    "    table with a nice format.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    summary : tuple\n",
    "        Tuple containing the lists with the papers information (title, author \n",
    "        and journal of publication).\n",
    "    line : integer, optional\n",
    "        Maximum line character length for printing the table. The default is\n",
    "        105 characters long.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    titles, authors, journals = summary\n",
    "    line = line//3*3  # Length of each line in the table\n",
    "    col = int(line/3)  # Length of each cell in the table\n",
    "    \n",
    "    print(\"#\"*line)  # Top border\n",
    "    \n",
    "    print(\"|    | Title \" + (col - 11) * \" \" + \n",
    "          \" | Author(s)\" + \" \"*(col-14) + \n",
    "          \" | Journal\" + \" \"*(col-12) + \" |\")  # Headers\n",
    "    \n",
    "    print(\"-\"*line)  # Header line separator\n",
    "    \n",
    "    for i, row in enumerate(zip(titles, authors, journals)):  # Paper info\n",
    "        print(\"| \", end = \"\")  # Left border\n",
    "        print(i + 1, end = (2-len(str(i + 1)))*\" \" + \" | \")  # Paper number\n",
    "        \n",
    "        for cell in row:  # Print row\n",
    "            n = len(cell.strip())\n",
    "            cell = cell[0:col - 5] if n > col - 5 else cell\n",
    "            cell = cell + \" \"*(col - 5 - n)\n",
    "            print(cell, end = \" | \")\n",
    "        print(\"\")\n",
    "        \n",
    "    print(\"#\"*line)  # Bottom border"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Search term (or group of terms) in PubMed\n",
    "\n",
    "This is the longest function in this notebook. It has two modes:\n",
    "\n",
    "- Default (```crawl = False```): all the papers that matched the query are printed in the form of a table (defined in **3.2.**) sequentially, until the user chooses a paper. Then, the PubMed URL of that publication is printed to the console and output by this function.\n",
    "\n",
    "- Crawling (```crawl = True```): the abstracts of all the papers are output in a list of tuples. If desired, also the paper title, author(s) and journal where the paper was published are included in the tuples. Also, the information can be stored in a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pubmed_search_term(term, crawl = False, title = False, author = False,\n",
    "                       journal = False, file = False):\n",
    "    \"\"\"\n",
    "    Query PubMed and get the desired information. Two modes: default for \n",
    "    point requests and \"crawl\" to get information about multiple papers at the\n",
    "    same time.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    term : string\n",
    "        The term, terms set or PubMed query to search for papers of interest.\n",
    "    crawl : boolean, optional\n",
    "        Set to False for point requests, and True to get information about\n",
    "        multiple papers at the same time. The default is False.\n",
    "    title : boolean, optional\n",
    "        Whether to include the paper title or not in the output. Only for \n",
    "        crawling mode. The default is False.\n",
    "    author : boolean, optional\n",
    "        Whether to include the paper authors or not in the output. Only for \n",
    "        crawling mode. The default is False.\n",
    "        DESCRIPTION. The default is False.\n",
    "    journal : boolean, optional\n",
    "        Whether to include the paper journal or not in the output. Only for \n",
    "        crawling mode. The default is False.\n",
    "    file : string, optional\n",
    "        The name of the file to be written with the required information, if \n",
    "        desired. The default is False.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    abstract_list : list\n",
    "        List with the required information about the papers of interest.\n",
    "\n",
    "    \"\"\"\n",
    "    pubmed_url = \"https://pubmed.ncbi.nlm.nih.gov\"\n",
    "    pubmed_query = pubmed_url + \"/?term={}\"\n",
    "    \n",
    "    term = term.replace(\" \", \"+\")\n",
    "    i = 0\n",
    "    url = pubmed_query.format(term)\n",
    "    abstract_list = []\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "            i += 1\n",
    "            search_url = url if i == 1 else url + \"&page=\" + str(i)\n",
    "            urls, summary = scrape_pubmed_query(search_url, file)\n",
    "            \n",
    "            if len(urls) == 0:\n",
    "                print(\"No more papers for your query!\")\n",
    "                break\n",
    "            \n",
    "            print_table_from_list(summary, line = 80)\n",
    "            if not crawl:\n",
    "                paper_num = input(\"Leave blank to see next results page,\\n\"\n",
    "                                  \"enter 'ABS' to show all abstracts\\n\"\n",
    "                                  \"or choose a paper (enter number): \")\n",
    "                print(\"\")\n",
    "            else:\n",
    "                paper_num = \"ABS\"\n",
    "            \n",
    "            if paper_num in \"12345678910\" and paper_num != \"\":                    \n",
    "                pmid = urls[str(int(paper_num) - 1)]\n",
    "                url = pubmed_url + pmid\n",
    "                print(\"The PubMed URL for this paper is: {}\".format(url))\n",
    "                return url\n",
    "            \n",
    "            elif paper_num == \"ABS\":\n",
    "                for n, paper in enumerate(urls.values()):\n",
    "                    page = get_webpage(pubmed_url + paper)\n",
    "                    time.sleep(1)  # Crawler delay in PubMed domain\n",
    "                    \n",
    "                    try:\n",
    "                        if crawl:\n",
    "                            output = (\"page{}, paper{}\".format(i,n+1),\n",
    "                                      show_abstract(page, crawl, file))\n",
    "                            if file:\n",
    "                                beg = 2\n",
    "                                end = -1\n",
    "                            else:\n",
    "                                beg = 0\n",
    "                                end = None\n",
    "                            for m, info in enumerate((journal, author, title)):\n",
    "                                if info:\n",
    "                                    output = ((output[0],) + \n",
    "                                              (summary[2-m][n][beg:end],) + \n",
    "                                              output[1:])\n",
    "                                \n",
    "                            print(str(i)+str(n+1), end = \", \")\n",
    "                            abstract_list.append(output)\n",
    "                            continue\n",
    "                        \n",
    "                        print(\"\\n\\n\"\n",
    "                              \"#######\\n\"\n",
    "                              \"## {} ##\\n\"\n",
    "                              \"#######\".format(str(n + 1)))\n",
    "                        \n",
    "                        show_abstract(page)\n",
    "                        \n",
    "                        if input(\"Go to SciHub? \").lower() in (\"yes\", \"y\", \"si\"):\n",
    "                            print(get_doi(page))\n",
    "                            time.sleep(3)\n",
    "                            \n",
    "                    except AttributeError:\n",
    "                        print(\"No abstract for paper {}\".format(n+1),\n",
    "                              end = \", \")\n",
    "                        \n",
    "                print(\"\")\n",
    "                \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"OK, it's time to quit...\")\n",
    "        \n",
    "    if crawl and file:\n",
    "        while True:\n",
    "            try:\n",
    "                assert(type(file) == type(\"a\"))\n",
    "                content = u\"\"\n",
    "                for paper in abstract_list:\n",
    "                    content += \";\".join(paper) + \"\\n\"\n",
    "                f = open(file, \"w\")\n",
    "                f.write(content)\n",
    "                f.close()\n",
    "                return abstract_list\n",
    "                \n",
    "            except AssertionError:\n",
    "                file = input(\"Please, introduce a valid file name: \")\n",
    "        \n",
    "    else:\n",
    "        return abstract_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Show abstract of a given paper\n",
    "\n",
    "This function gets the abstract of a paper and returns it after formatting (if necessary) with the function defined in **3.5**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_abstract(page, crawl = False, file = False):\n",
    "    \"\"\"\n",
    "    Parses the HTML file of a PubMed entry and finds the abstract of the paper.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    page : string\n",
    "        HTML file of the paper whose abstract is to be found.\n",
    "    crawl : boolean, optional\n",
    "        If True, the abstract is output but not printed to the console. The\n",
    "        default is False.\n",
    "    file : string, optional\n",
    "        The name of the file where the results of the crawling will be written. \n",
    "        The default is False.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    abstract : string\n",
    "        The abstract of the paper of interest, with an adequate format for the\n",
    "        task.\n",
    "\n",
    "    \"\"\"\n",
    "    soup = bs(page, \"html.parser\")\n",
    "    abstract = soup.find(\"div\", id=\"enc-abstract\")\n",
    "    if crawl and file:\n",
    "        abstract = prepare_text(abstract, \n",
    "                                replace_for_csv = True)\n",
    "        return abstract\n",
    "    elif crawl:\n",
    "        abstract = prepare_text(abstract, encode = False)\n",
    "        return abstract\n",
    "    else:\n",
    "        print(\"{}\".format(abstract.text.strip()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5. Prepare text\n",
    "\n",
    "Prepares the text as needed, i.e., if the text is to be printed to a file, it needs to be encoded as UTF-8 first. Also, in the output file the different fields will be separated by a character (```sep```): it is important that this character is replaced in the original text to avoid problems when opening the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_text(soup, replace_for_csv = False, sep = \";\", encode = True):\n",
    "    \"\"\"\n",
    "    Prepares a text from a bs4.BeautifulSoup, removing leading and trailing\n",
    "    spaces and newlines by default.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    soup : bs4.BeautifulSoup\n",
    "        BeautifulSoup object where the desired text is enclosed.\n",
    "    replace_for_csv : boolean, optional\n",
    "        Whether the text has to be prepared to be written to a (csv) file or\n",
    "        not. The default is False.\n",
    "    sep : string, optional\n",
    "        The separator in the output file. It prevents the future file from\n",
    "        being wrongly formatted by replacing the future separator by ',.'. The\n",
    "        default is \";\".\n",
    "    encode : boolean, optional\n",
    "        Whether to encode or not the text as UTF-8. It prevents encoding errors\n",
    "        when writting a new file. The default is True.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    text : string\n",
    "        The text, ready to be printed/stored.\n",
    "\n",
    "    \"\"\"\n",
    "    text = soup.text.strip()\n",
    "    \n",
    "    if replace_for_csv:\n",
    "        text = text.replace(sep, \",.\").replace(\"\\t\", \" \").replace(\"\\n\", \" \")\n",
    "        \n",
    "    if encode:\n",
    "        text = str(text.encode(\"utf-8\"))\n",
    "        \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6. Get webpage\n",
    "\n",
    "To avoid writting \"requests.get(...).text\" every time I am requesting a webpage, I prefered to write this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_webpage(url):\n",
    "    \"\"\"\n",
    "    Requests a given webpage and returns its text content.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    url : string\n",
    "        URL of the webpage to be searched.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    text : string\n",
    "        Text of the required webpage.\n",
    "\n",
    "    \"\"\"\n",
    "    text = requests.get(url).text\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7. Get DOI of a publication\n",
    "\n",
    "Finds the DOI of a given paper. The DOI of a paper might be useful for some tasks that now I don't remember."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doi(paper_page):\n",
    "    \"\"\"\n",
    "    Finds the DOI of the desired paper.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    paper_page : string\n",
    "        HTML file of the paper of interest.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    doi : string\n",
    "        The DOI of the paper.\n",
    "\n",
    "    \"\"\"\n",
    "    scihub_url = \"https://sci-hub.st/\"\n",
    "    soup = bs(paper_page, \"html.parser\")\n",
    "    \n",
    "    doi = soup.find(\"a\", {\"class\": \"id-link\", \"data-ga-action\": \"DOI\"}).text\n",
    "    url = scihub_url + doi\n",
    "    \n",
    "    return doi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8. Print an introduction to the console when running this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_intro():\n",
    "    \"\"\"\n",
    "    Prints an introduction to the console when the script is run.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None.\n",
    "\n",
    "    \"\"\"\n",
    "    intro = \"\"\"\n",
    "    Hi! Welcome to my script. By running this code, first you will have to \n",
    "    introduce some words to query in PubMed (if you know some structured PubMed \n",
    "    query, you can also introduce it).\\n\n",
    "    \\n\n",
    "    As a result, a table with the first results will be printed.\n",
    "    \\n\n",
    "    You can enter a number to obtain a paper's PubMed URL,\\n\n",
    "    leave a blank spaceto look for more results,\\n\n",
    "    or enter 'ABS' to show the abstracts ofall the papers in the table.\\n\n",
    "    Within this last mode, you can obtain the SciHub URL for each paper\\n\n",
    "    if you want to read the whole paper.\\n\"\"\"\n",
    "    \n",
    "    print(intro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Obtain information from PubMed\n",
    "\n",
    "Let's scrape PubMed using the previous functions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. A single paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Hi! Welcome to my script. By running this code, first you will have to \n",
      "    introduce some words to query in PubMed (if you know some structured PubMed \n",
      "    query, you can also introduce it).\n",
      "\n",
      "    \n",
      "\n",
      "    As a result, a table with the first results will be printed.\n",
      "    \n",
      "\n",
      "    You can enter a number to obtain a paper's PubMed URL,\n",
      "\n",
      "    leave a blank spaceto look for more results,\n",
      "\n",
      "    or enter 'ABS' to show the abstracts ofall the papers in the table.\n",
      "\n",
      "    Within this last mode, you can obtain the SciHub URL for each paper\n",
      "\n",
      "    if you want to read the whole paper.\n",
      "\n",
      "Please, enter your query: trpa1\n",
      "##############################################################################\n",
      "|    | Title                 | Author(s)             | Journal               |\n",
      "------------------------------------------------------------------------------\n",
      "| 1  | TRPA1: a molecular vi | Meents JE, Ciotu CI,  | J Neurophysiol. 2019. | \n",
      "| 2  | TRPA1.                | Zygmunt PM, Högestätt | Handb Exp Pharmacol.  | \n",
      "| 3  | Mammalian Transient R | Talavera K, Startek J | Physiol Rev. 2020.    | \n",
      "| 4  | The TRPA1 channel in  | Nassini R, Materazzi  | Rev Physiol Biochem P | \n",
      "| 5  | ROS/TRPA1/CGRP signal | Jiang L, Ma D, Grubb  | J Headache Pain. 2019 | \n",
      "| 6  | TRPA1 channel contrib | Conklin DJ, Guo Y, Ny | Am J Physiol Heart Ci | \n",
      "| 7  | TRPA1 Channel as a Re | Logashina YA, Korolko | Biochemistry (Mosc).  | \n",
      "| 8  | [Roles of TRPA1 in Pa | So K.                 | Yakugaku Zasshi. 2020 | \n",
      "| 9  | Structural Insights i | Suo Y, Wang Z, Zubcev | Neuron. 2020.         | \n",
      "| 10 | Roles of TRPA1 and TR | Wang M, Zhang Y, Xu M | Free Radic Biol Med.  | \n",
      "##############################################################################\n",
      "Leave blank to see next results page,\n",
      "enter 'ABS' to show all abstracts\n",
      "or choose a paper (enter number): 2\n",
      "\n",
      "The PubMed URL for this paper is: https://pubmed.ncbi.nlm.nih.gov/24756722/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://pubmed.ncbi.nlm.nih.gov/24756722/'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_intro()\n",
    "pubmed_search_term(input(\"Please, enter your query: \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Multiple papers\n",
    "\n",
    "To avoid overloading PubMed just because of a simple demonstration, I'm using KeyboardInterrupt (Ctrl+C) after 43 papers have been fetched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please, enter your query: trpa1\n",
      "##############################################################################\n",
      "|    | Title                 | Author(s)             | Journal               |\n",
      "------------------------------------------------------------------------------\n",
      "| 1  | TRPA1: a molecular vi | Meents JE, Ciotu CI,  | J Neurophysiol. 2019. | \n",
      "| 2  | TRPA1.                | Zygmunt PM, Högestätt | Handb Exp Pharmacol.  | \n",
      "| 3  | Mammalian Transient R | Talavera K, Startek J | Physiol Rev. 2020.    | \n",
      "| 4  | The TRPA1 channel in  | Nassini R, Materazzi  | Rev Physiol Biochem P | \n",
      "| 5  | ROS/TRPA1/CGRP signal | Jiang L, Ma D, Grubb  | J Headache Pain. 2019 | \n",
      "| 6  | TRPA1 channel contrib | Conklin DJ, Guo Y, Ny | Am J Physiol Heart Ci | \n",
      "| 7  | TRPA1 Channel as a Re | Logashina YA, Korolko | Biochemistry (Mosc).  | \n",
      "| 8  | [Roles of TRPA1 in Pa | So K.                 | Yakugaku Zasshi. 2020 | \n",
      "| 9  | Structural Insights i | Suo Y, Wang Z, Zubcev | Neuron. 2020.         | \n",
      "| 10 | Roles of TRPA1 and TR | Wang M, Zhang Y, Xu M | Free Radic Biol Med.  | \n",
      "##############################################################################\n",
      "11, 12, 13, 14, 15, 16, 17, 18, 19, 110, \n",
      "##############################################################################\n",
      "|    | Title                 | Author(s)             | Journal               |\n",
      "------------------------------------------------------------------------------\n",
      "| 1  | TRPA1 regulates macro | Wang Q, Chen K, Zhang | Atherosclerosis. 2020 | \n",
      "| 2  | A Cell-Penetrating Sc | Lin King JV, Emrick J | Cell. 2019.           | \n",
      "| 3  | Schwann cell TRPA1 me | De Logu F, Nassini R, | Nat Commun. 2017.     | \n",
      "| 4  | miRNA-711 Binds and A | Han Q, Liu D, Convert | Neuron. 2018.         | \n",
      "| 5  | TRPA1.                | García-Añoveros J, Na | Handb Exp Pharmacol.  | \n",
      "| 6  | The TRPA1 Channel in  | Wang Z, Ye D, Ye J, W | Front Pharmacol. 2019 | \n",
      "| 7  | TRPA1 inhibition amel | Wang Z, Xu Y, Wang M, | EBioMedicine. 2018.   | \n",
      "| 8  | Schwann cells express | De Logu F, Li Puma S, | J Clin Invest. 2019.  | \n",
      "| 9  | TRPA1 receptors in ch | Morice AH.            | Pulm Pharmacol Ther.  | \n",
      "| 10 | TRPA1 mediates formal | McNamara CR, Mandel-B | Proc Natl Acad Sci U  | \n",
      "##############################################################################\n",
      "21, 22, 23, 24, 25, 26, 27, 28, No abstract for paper 9, 210, \n",
      "##############################################################################\n",
      "|    | Title                 | Author(s)             | Journal               |\n",
      "------------------------------------------------------------------------------\n",
      "| 1  | TRPA1 and issues rela | Lindsay CD, Timperley | Hum Exp Toxicol. 2020 | \n",
      "| 2  | A Human TRPA1-Specifi | Heber S, Gold-Binder  | J Neurosci. 2019.     | \n",
      "| 3  | Behavioral characteri | Reese RM, Dourado M,  | Sci Rep. 2020.        | \n",
      "| 4  | Polymodal Nociception | Gu P, Gong J, Shang Y | Curr Biol. 2019.      | \n",
      "| 5  | TRPA1/NOX in the soma | Marone IM, De Logu F, | Brain. 2018.          | \n",
      "| 6  | TRPA1 mediates the in | Bautista DM, Jordt SE | Cell. 2006.           | \n",
      "| 7  | The role of Na(v)1.7  | Cheng RX, Feng Y, Liu | Theranostics. 2019.   | \n",
      "| 8  | Recent Progress in th | Skerratt S.           | Prog Med Chem. 2017.  | \n",
      "| 9  | Inhibition of Ligand- | Ton HT, Phan TX, Aher | Mol Pharmacol. 2020.  | \n",
      "| 10 | Transient receptor po | Chen H, Terrett JA.   | Expert Opin Ther Pat. | \n",
      "##############################################################################\n",
      "31, 32, 33, 34, 35, 36, 37, 38, 39, 310, \n",
      "##############################################################################\n",
      "|    | Title                 | Author(s)             | Journal               |\n",
      "------------------------------------------------------------------------------\n",
      "| 1  | Voltage-dependent mod | Shen X, Wang Q, Lin Y | Cell Calcium. 2020.   | \n",
      "| 2  | TRPA1 as a therapeuti | Souza Monteiro de Ara | Expert Opin Ther Targ | \n",
      "| 3  | Transient receptor po | Alavi MS, Shamsizadeh | Toxicol Mech Methods. | \n",
      "| 4  | Molecular basis of TR | Kádková A, Synytsya V | Physiol Res. 2017.    | \n",
      "| 5  | Noxious compounds act | Macpherson LJ, Dubin  | Nature. 2007.         | \n",
      "| 6  | An inflammatory stimu | Yap JMG, Ueda T, Take | Cytokine. 2020.       | \n",
      "| 7  | Blocking TRPA1 in Res | Mukhopadhyay I, Kulka | Pharmaceuticals (Base | \n",
      "| 8  | TRPA1-expressing lami | Yang Y, Wang S, Kobay | JCI Insight. 2019.    | \n",
      "| 9  | A Non-covalent Ligand | Liu C, Reese R, Vu S, | Neuron. 2021.         | \n",
      "| 10 | TRPA1 Expression in S | De Logu F, Ugolini F, | Biomolecules. 2020.   | \n",
      "##############################################################################\n",
      "OK, it's time to quit...\n"
     ]
    }
   ],
   "source": [
    "abstracts = pubmed_search_term(input(\"Please, enter your query: \"),\n",
    "                               crawl = True,\n",
    "                               title = True, \n",
    "                               author = True,\n",
    "                               journal = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what is the output of this function when searching for multiple papers (only first 3 publications are shown):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# page1, paper1\n",
      "Title:\n",
      "TRPA1: a molecular view.\n",
      "Author(s):\n",
      "Meents JE, Ciotu CI, Fischer MJM.\n",
      "Journal:\n",
      "J Neurophysiol. 2019.\n",
      "Abstract:\n",
      "The transient receptor potential ankyrin 1 (TRPA1) ion channel is expressed in pain-sensing neurons and other tissues and has become a major target in the development of novel pharmaceuticals. A remarkable feature of the channel is its long list of activators, many of which we are exposed to in daily life. Many of these agonists induce pain and inflammation, making TRPA1 a major target for anti-inflammatory and analgesic therapies. Studies in human patients and in experimental animals have confirmed an important role for TRPA1 in a number of pain conditions. Over the recent years, much progress has been made in elucidating the molecular structure of TRPA1 and in discovering binding sites and modulatory sites of the channel. Because the list of published mutations and important molecular sites is steadily growing and because it has become difficult to see the forest for the trees, this review aims at summarizing the current knowledge about TRPA1, with a special focus on the molecular structure and the known binding or gating sites of the channel.\n",
      "\n",
      "\n",
      "# page1, paper2\n",
      "Title:\n",
      "TRPA1.\n",
      "Author(s):\n",
      "Zygmunt PM, Högestätt ED.\n",
      "Journal:\n",
      "Handb Exp Pharmacol. 2014.\n",
      "Abstract:\n",
      "The transient receptor potential ankyrin subtype 1 protein (TRPA1) is a nonselective cation channel permeable to Ca(2+), Na(+), and K(+). TRPA1 is a promiscuous chemical nocisensor that is also involved in noxious cold and mechanical sensation. It is present in a subpopulation of Aδ- and C-fiber nociceptive sensory neurons as well as in other sensory cells including epithelial cells. In primary sensory neurons, Ca(2+) and Na(+) flowing through TRPA1 into the cell cause membrane depolarization, action potential discharge, and neurotransmitter release both at peripheral and central neural projections. In addition to being activated by cysteine and lysine reactive electrophiles and oxidants, TRPA1 is indirectly activated by pro-inflammatory agents via the phospholipase C signaling pathway, in which cytosolic Ca(2+) is an important regulator of channel gating. The finding that non-electrophilic compounds, including menthol and cannabinoids, activate TRPA1 may provide templates for the design of non-tissue damaging activators to fine-tune the activity of TRPA1 and raises the possibility that endogenous ligands sharing binding sites with such non-electrophiles exist and regulate TRPA1 channel activity. TRPA1 is promising as a drug target for novel treatments of pain, itch, and sensory hyperreactivity in visceral organs including the airways, bladder, and gastrointestinal tract.\n",
      "\n",
      "\n",
      "# page1, paper3\n",
      "Title:\n",
      "Mammalian Transient Receptor Potential TRPA1 Channels: From Structure to Disease.\n",
      "Author(s):\n",
      "Talavera K, Startek JB, Alvarez-Collazo J, Boonen B, Alpizar YA, Sanchez A, Naert R, Nilius B.\n",
      "Journal:\n",
      "Physiol Rev. 2020.\n",
      "Abstract:\n",
      "The transient receptor potential ankyrin (TRPA) channels are Ca2+-permeable nonselective cation channels remarkably conserved through the animal kingdom. Mammals have only one member, TRPA1, which is widely expressed in sensory neurons and in non-neuronal cells (such as epithelial cells and hair cells). TRPA1 owes its name to the presence of 14 ankyrin repeats located in the NH2 terminus of the channel, an unusual structural feature that may be relevant to its interactions with intracellular components. TRPA1 is primarily involved in the detection of an extremely wide variety of exogenous stimuli that may produce cellular damage. This includes a plethora of electrophilic compounds that interact with nucleophilic amino acid residues in the channel and many other chemically unrelated compounds whose only common feature seems to be their ability to partition in the plasma membrane. TRPA1 has been reported to be activated by cold, heat, and mechanical stimuli, and its function is modulated by multiple factors, including Ca2+, trace metals, pH, and reactive oxygen, nitrogen, and carbonyl species. TRPA1 is involved in acute and chronic pain as well as inflammation, plays key roles in the pathophysiology of nearly all organ systems, and is an attractive target for the treatment of related diseases. Here we review the current knowledge about the mammalian TRPA1 channel, linking its unique structure, widely tuned sensory properties, and complex regulation to its roles in multiple pathophysiological conditions.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, paper in enumerate(abstracts):\n",
    "    if i > 2: break\n",
    "    \n",
    "    print(\"# \"+ paper[0])\n",
    "    print(\"Title:\\n\" + paper[1])\n",
    "    print(\"Author(s):\\n\" + paper[2])\n",
    "    print(\"Journal:\\n\" + paper[3])\n",
    "    print(\"Abstract:\\n\" + paper[4])\n",
    "    print(\"\\n\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
